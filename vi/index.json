[
{
	"uri": "/vi/1-awsarchitectureblog/",
	"title": "AWS Architecture Blog",
	"tags": [],
	"description": "",
	"content": "AWS Architecture Blog  Insights for CTOs: Part 3 – Phát triển kinh doanh với năng lực dữ liệu hiện đại Dream11: Ngặn chặn các cuộc tấn công qui mô lớn ở lớp ứng dụng bằng AWS WAF Triển khai ứng dụng dựa trên Quarkus sử dụng AWS Lambda với AWS SAM  "
},
{
	"uri": "/vi/",
	"title": "AWS Vietnamese Blog",
	"tags": [],
	"description": "",
	"content": "AWS Vietnamese Blog Nội dung    AWS Architecture Blog\n Insights for CTOs: Part 3 – Phát triển kinh doanh với năng lực dữ liệu hiện đại Dream11: Ngặn chặn các cuộc tấn công qui mô lớn ở lớp ứng dụng bằng AWS WAF Triển khai ứng dụng dựa trên Quarkus sử dụng AWS Lambda với AWS SAM      Windows on AWS  Khởi chạy Microsoft Windows Server instances trên Amazon EC2 nhanh hơn tới 65% so với trước đây      Networking on AWS  Giảm chi phí và tăng cường bảo mật với Amazon VPC Endpoints      Data Analytics  Những điều cần quan tâm khi dịch chuyển Data warehouse lên Amazon Redshift     "
},
{
	"uri": "/vi/3-networkingonaws/3.1-blog-1/",
	"title": "Giảm chi phí và tăng cường bảo mật với Amazon VPC Endpoints",
	"tags": [],
	"description": "",
	"content": "Giảm chi phí và tăng cường bảo mật với Amazon VPC Endpoints Bài viết này sẽ giải thích những lợi ích của việc sử dụng Amazon VPC endpoints và giới thiệu một self-paced workshop, chúng tôi sẽ giúp bạn tìm hiểu thêm về chúng. Amazon Virtual Private Cloud (Amazon VPC) cho phép bạn khởi chạy các tài nguyên của Amazon Web Services (AWS) vào một mạng ảo mà bạn đã xác định. Mạng ảo này giống mạng truyền thống mà bạn sẽ vận hành trong trung tâm dữ liệu của riêng mình. Lợi ích bổ sung là khả năng sử dụng cơ sở hạ tầng có thể mở rộng của AWS.\nVPC endpoint cho phép bạn kết nối riêng VPC của mình với các dịch vụ mà AWS hỗ trợ. Nó không yêu cầu bạn triển khai internet gateway và thiết bị network address translation (NAT) , kết nối Virtual Private Network (VPN), hoặc kết nối AWS Direct Connect. Endpoints là các thiết bị ảo được mở rộng qui mô theo chiều ngang, có dự phòng, và tính khả dụng cao. VPC endpoints cho phép giao tiếp giữa các instances trong VPC và các dịch vụ của bạn mà không gây ra bất cứ rủi ro nào về tính khả dụng hoặc hạn chế băng thông đối với network traffic của bạn.\nBạn có thể tối ưu hóa network path bằng cách tránh lưu lượng truy cập đến các internet gateways và các chi phí phát sinh đến NAT gateways, NAT instances hoặc phải duy trì các firewalls. VPC endpoints cũng cung cấp cho bạn khả năng kiểm soát tốt hơn nhiều đối với người dùng và các ứng dụng truy cập các dịch vụ của AWS. Có ba loại VPC endpoints: gateway load balancer endpoints, gateway endpoints và interface endpoints. Hãy cùng xem xét từng loại endpoint và cách chúng được sử dụng.\nLoại endpoint đầu tiên, Gateway Load Balancer endpoint, cho phép bạn chặn lưu lượng và định tuyến nó đến mạng hoặc các dịch vụ bảo mật mà bạn đã cấu hình bằng Gateway Load Balancer. Gateway Load Balancer cho phép bạn triển khai, mở rộng quy mô và quản lý các thiết bị ảo, chẳng hạn như tường lửa, hệ thống phát hiện và ngăn chặn xâm nhập và hệ thống kiểm tra gói tin chi tiết. Đồng nghiệp của chúng tôi, Justin Davies đã viết một bài đăng trên blog xuất sắc về supported architectural patterns using AWS Gateway Load Balancers.\nLoại endpoint thứ hai, Gateway endpoint, cho phép bạn cung cấp quyền truy cập vào Amazon Simple Storage Service (S3) và Amazon DynamoDB. Bạn có thể cấu hình resource policies trên cả gateway endpoint và tài nguyên AWS mà endpoint cung cấp quyền truy cập. VPC endpoint policy là resource policy AWS Identity and Access Management (AWS IAM) mà bạn có thể đính kèm vào một endpoint. Đây là một policy riêng để kiểm soát truy cập từ endpoint đến dịch vụ được chỉ định. Điều này cho phép kiểm soát truy cập chi tiết và kết nối mạng riêng từ bên trong VPC. Ví dụ: bạn có thể tạo một policy hạn chế quyền truy cập vào một DynamoDB table cụ thể. Policy này sẽ chỉ cho phép một số người dùng hoặc nhóm nhất định truy cập vào bảng thông qua VPC endpoint.\n Hình 1: Truy cập Amazon S3 thông qua một Gateway VPC endpoint   Loại endpoint thứ ba, Interface endpoint, cho phép bạn kết nối với các dịch vụ được hỗ trợ bởi AWS PrivateLink. Điều này bao gồm một số lượng lớn các dịch vụ AWS. Nó cũng có thể bao gồm các dịch vụ được quản lý bởi các khách hàng AWS khác và các đối tác của AWS Partner Network (APN) trong VPCs của riêng họ. Bằng cách sử dụng AWS partner services thông qua AWS PrivateLink, bạn không còn phải phụ thuộc các quyền truy cập vào public internet. Phí truyền dữ liệu cho lưu lượng truy cập từ Amazon EC2 đến internet thay đổi tùy theo khối lượng. Sau 1 GB / tháng đầu tiên (0,00 đô la mỗi GB), dữ liệu được tính phí ở mức 0,09 đô la / GB (đối với AWS US-East 1 Virginia). Giống như gateway endpoints, interface endpoints có thể được bảo mật bằng cách sử dụng các resource policies trên chính endpoint và resource mà endpoint cung cấp quyền truy cập. Interface endpoints cho phép sử dụng các security group để hạn chế quyền truy cập vào endpoint.\n Hình 2: Truy cập vào QLDB thông qua một interface VPC endpoint   Thiết kế mạng hiện có của một số tổ chức có thể ảnh hưởng đến nơi triển khai các VPC Endpoints. Trong các môi trường có nhiều tài khoản AWS, thiết kế mạng có thể khác nhau đáng kể. Hãy xem xét một tổ chức đã xây dựng kiến trúc network hub-and-spoke với AWS Transit Gateway. VPCs đã được cấp phép cho nhiều tài khoản AWS, để tạo điều kiện giúp tách biệt các network hoặc để cho phép tính năng quản trị network uỷ quyền.\nĐối với các kiến trúc phân tán, bạn có thể xây dựng một “shared services” VPC, cung cấp quyền truy cập tập trung vào các dịch vụ được chia sẻ theo yêu cầu của khối lượng công việc trong mỗi VPC. Các dịch vụ dùng chung này có thể bao gồm các tài nguyên như directory services hoặc VPC endpoints. Chia sẻ resources từ một vị trí trung tâm thay vì xây dựng chúng trong từng VPC có thể giảm chi phí và các chi phí quản lý.\nCách tiếp cận này đã được đồng nghiệp của chúng tôi là Bhavin Desai nêu ra trong bài đăng trên blog của anh ấy, Centralized DNS management of hybrid cloud with Amazon Route 53 and AWS Transit Gateway. Thay vì tập trung triển khai VPC endpoint, người thiết kế network có thể chọn triển khai endpoints trong một spoke VPC để đảm bảo nó gần với một workload duy nhất sẽ sử dụng endpoint. Điều này có thể hỗ trợ các vấn đề về bảo mật hoặc hiệu suất cụ thể của workload. Với mỗi cách tiếp cận, tập trung và phân quyền, đều mang lại những lợi ích riêng. Người ta thường sử dụng cả hai để đáp ứng các yêu cầu cụ thể của mình trong từng trường hợp.\n Hình 3: VPC endpoints tập trung ( nhiều VPCs)   Ngoài ra, một tổ chức đã tập trung network của mình và chọn tận dụng chia sẻ VPC để cho phép nhiều tài khoản AWS tạo tài nguyên ứng dụng. Cách tiếp cận như vậy cho phép tổng hợp các EC2 instance, cơ sở dữ liệu Amazon Relational Database Service (RDS) và các AWS Lambda functions hoạt động thành một mạng chia sẻ, được quản lý tập trung. Với cả hai mô hình, việc thiết lập một bộ kiểm soát chi tiết để hạn chế quyền truy cập vào tài nguyên là rất quan trọng để hỗ trợ các bảo mật cho tổ chức và đáp ứng các mục tiêu về compliance. Đồng thời giúp duy trì hiệu quả hoạt động.\n Hình 4: VPC endpoints tập trung ( nhiều VPCs)   Tìm hiểu cách sử dụng với VPC Endpoint Workshop Để hiểu hơn về cách hạn chế quyền truy cập vào các endpoints và các dịch vụ mà chúng kết nối có thể gây nhầm lẫn. Tìm hiểu thêm bằng cách tham gia VPC Endpoint Workshop. Nó sẽ giúp bạn cải thiện tình trạng bảo mật của các workload trên cloud của bạn bằng cách sử dụng các network controls và VPC endpoint policies để quản lý quyền truy cập vào tài nguyên AWS.\n"
},
{
	"uri": "/vi/1-awsarchitectureblog/1.1-blog-1/",
	"title": "Insights for CTOs: Part 3 – Phát triển kinh doanh với năng lực dữ liệu hiện đại",
	"tags": [],
	"description": "",
	"content": "Bài đăng này được viết cùng với với Jonathan Hwang, người đứng đầu [Foundation Data Analytics tại Zendesk. Với vai trò là Senior Solutions Architect, tôi đã nói chuyện với các Chief technology officers (CTOs) và ban lãnh đạo điều hành của các doanh nghiệp lớn như các ngân hàng lớn, các doanh nghiệp software as a service (SaaS), các doanh nghiệp SMB và các công ty khởi nghiệp.\nQua 6 phần trong bài viết này, tôi sẽ chia sẻ những hiểu biết và kiến thức được tổng hợp từ nhiều Giám đốc Công nghệ và các nhà Lãnh đạo Kỹ thuật trong hành trình áp dụng công nghệ Điện toán đám mây. Dưới đây là những đúc kết về các cách áp dụng hay nhất về kiến trúc Điện toán đám mây được xây dựng trên kết quả thực hành của tôi để giúp bạn xây dựng và điều hành thành công các ứng dụng trên Cloud. Các cách áp dụng đa dạng khía cạnh bao gồm Xây dựng và vận hành ứng dụng, Bảo mật, Quản lý tài chính , Trí tuệ nhân tạo, các mô hình vận hành và chiến lược để dịch chuyển lên Cloud.\nTrong Phần 3, cùng với người đứng đầu Foundation Analytics tại Zendesk, Jonathan Hwang, chúng tôi chỉ ra cách Zendesk từng bước mở rộng dữ liệu và khả năng phân tích của họ để sử dụng hiệu quả nguồn dữ liệu và thông tin mà họ thu thập được từ những tương tác của khách hàng. Bạn có thể tìm hiểu cách Zendesk xây dựng một kiến trúc dữ liệu hiện đại bằng cách sử dụng dịch vụ Amazon Simple Storage Service (Amazon S3) để lưu trữ, Apache Hudi để xử lý dữ liệu phân cấp và AWS Lake Formation để kiểm soát truy cập chi tiết.\nTại sao Zendesk cần xây dựng và mở rộng quy mô nền tảng dữ liệu của họ Zendesk là một nền tảng dịch vụ khách hàng, nơi kết nối hơn 100.000 thương hiệu với hàng trăm triệu khách hàng qua điện thoại, trò chuyện, email, nhắn tin, các kênh xã hội, cộng đồng, trang web đánh giá và trung tâm trợ giúp. Họ thu thập và sử dụng dữ liệu từ các kênh này để đưa ra các quyết định cho chiến lược kinh doanh tốt nhất và tạo ra các sản phẩm mới và cải tiến các sản phẩm khác.\nVào năm 2014, đội ngũ chuyên về dữ liệu của Zendesk đã xây dựng phiên bản đầu tiên của nền tảng dữ liệu lớn (Big Data) trong trung tâm dữ liệu của riêng họ bằng cách sử dụng Apache Hadoop để áp dụng Máy học (Machine Learning). Cùng với đó, họ đã tung ra Answer Bot và Zendesk Benchmark report. Những sản phẩm này rất thành công đến nỗi chúng sớm sử dụng hết tài nguyên tính toán có sẵn trong trung tâm dữ liệu.\nVào cuối năm 2017, Zendesk nhận định rõ ràng nhu cầu cấp thiết của họ về việc hiện đại hóa dữ liệu và nhân rộng khả năng xử lý dữ liệu bằng cách dịch chuyển lên Đám mây (Cloud)\nNgày càng hiện đại hóa khả năng xử lý dữ liệu Zendesk đã xây dựng và mở rộng khối lượng công việc của họ để sử dụng các hồ chứa dữ liệu (data lakes) trên AWS, nhưng họ sớm gặp phải những thách thức về kiến trúc mới:\n Quy tắc \u0026ldquo;right to be forgotten\u0026rdquo; trong General Data Protection Regulation (GDPR) đã gây khó khăn và tốn kém cho việc duy trì các hồ chứa dữ liệu (data lakes), bởi vì việc xóa một phần dữ liệu nhỏ cần phải xử lý lại các bộ dữ liệu lớn. Gặp khó khăn trong việc quản lý về Bảo Mật và Quản trị hơn khi hồ chứa dữ liệu (data lakes) được mở rộng cho một lượng người dùng lớn hơn.  Các phần sau đây cho bạn biết cách Zendesk đang giải quyết các quy tắc GDPR bằng cách phát triển từ các tệp Apache Parquet thuần trên Amazon S3 thành các Hudi dataset trên Amazon S3 để cho phép chèn / cập nhật / xóa ở mức độ dòng. Để giải quyết vấn đề bảo mật và quản trị, Zendesk đang chuyển sang AWS Lake Formation Bảo mật tập trung để kiểm soát truy cập chi tiết trên quy mô lớn.\nNền tảng dữ liệu của Zendesk Hình 1 mô phỏng nền tảng dữ liệu hiện tại của Zendesk. Nền tảng hiện tại bao gồm ba đường dẫn dữ liệu (data pipelines): “Data Hub,” “Data Lake,” and “Self Service.”\n Hình 1. Zendesk data pipelines   Data Lake pipelines Data Lake và Data Hub pipelines bao gồm toàn bộ vòng đời của dữ liệu từ khi được thu thập đến khi được sử dụng.\nData Lake pipelines hợp nhất dữ liệu từ cơ sở dữ liệu có độ phân tán cao của Zendesk thành một hồ chứa dữ liệu (data lake) để phân tích.\nZendesk sử dụng Amazon Database Migration Service (AWS DMS) để thực hiện change data capture (CDC) từ hơn 1.800 Amazon Aurora MySQL databases trong 8 AWS Regions. Nó phát hiện các transaction bị thay đổi và cập nhật chúng vào hồ chứa dữ liệu (data lake) bằng cách sử dụng Amazon EMR và Hudi.\nZendesk ticket data bao gồm hơn 10 tỷ sự kiện và có quy mô lên đến petabyte dữ liệu. Các file trong hồ chứa dữ liệu (data lake) trong Amazon S3 được chuyển đổi và lưu trữ ở định dạng Apache Hudi và được đăng ký trên AWS Glue catalog và nó luôn sẵn sàng với tư cách là bảng dữ liệu để phục vụ cho truy vấn phân tích qua Amazon Athena.\nData Hub pipelines Các Data Hub pipelines tập trung vào các sự kiện ở thời gian thực và các trường hợp sử dụng phân tích dữ liệu streaming (streaming analytics ) với Apache Kafka. Bất kỳ ứng dụng nào tại Zendesk đều có thể đưa các sự kiện lên global Kafka message bus. Apache Flink nhập các sự kiện này vào Amazon S3.\nData Hub cung cấp dữ liệu doanh nghiệp chất lượng cao, có tính khả dụng và khả năng nhân rộng cao.\nSelf-managed pipeline Các đường dẫn dữ liệu tự quản lý cho phép các đội kỹ sư sản phẩm sử dụng hồ chứa dữ liệu (data lake) cho những trường hợp sử dụng không phù hợp với các mẫu tích hợp tiêu chuẩn. Tất cả các đội kỹ sư sản phẩm trong nội bộ của Zendesk có thể sử dụng các công cụ cơ bản như Amazon EMR, Amazon S3, Athena, và AWS Glue để xuất bản bộ dữ liệu phân tích của riêng họ và chia sẻ với các đội khác.\nMột ví dụ đáng chú ý về vấn đề này là từ nhóm kỹ sư phát hiện sự gian lận ( fraud detection ) của Zendesk. Họ xuất bản dữ liệu và phát hiện gian lận thông qua nền tảng hồ chứa dữ liệu tự quản lý của chúng tôi và sử dụng Amazon QuickSight để trực quan hóa.\nBạn cần mô hình bảo mật và tuân thủ chi tiết Các hồ chứa dữ liệu có thể thúc đẩy tăng trưởng thông qua việc ra quyết định và đổi mới sản phẩm nhanh hơn. Tuy nhiên, chúng cũng có thể mang đến những thách thức mới về bảo mật và tuân thủ:\nKhả năng Hiển thị và Khả năng Kiểm tra. Ai có quyền truy cập vào dữ liệu nào? Mọi người có cấp độ truy cập nào và làm thế nào / khi nào và ai đang truy cập nó? Kiểm soát quyền truy cập cụ thể. Làm cách nào để bạn xác định và thực thi quyền truy cập đặc quyền ít nhất vào các tập con dữ liệu trên quy mô lớn mà không tạo ra tắc nghẽn hoặc sự phụ thuộc vào yếu tố con người /đội ngũ chủ chốt.\nLake Formation giúp giải quyết những khúc mắc này bằng cách kiểm tra quyền truy cập dữ liệu và cung cấp bảo mật cấp dòng và cột cũng như mô hình kiểm soát truy cập được ủy quyền để tạo ra các trình quản lý dữ liệu cho hệ thống Bảo Mật và Quản Trị của bạn\nZendesk đã sử dụng Lake Formation để xây dựng một mô hình kiểm soát truy cập chi tiết sử dụng Bảo mật cấp dòng. Nó phát hiện các loại dữ liệu và thông tin cá nhân (Personally Identifiable Information - PII) ngay cả khi mở rộng qui mô hồ chứa dữ liệu (data lake).\nMột số khách hàng của Zendesk từ chối đưa dữ liệu và thông tin của họ vào hệ thống Máy học (Machine Learning) hoặc trong các dự án khảo sát thị trường. Zendesk sử dụng Lake Formation để áp dụng bảo mật cấp hàng nhằm lọc ra các hồ sơ liên quan đến danh sách tài khoản khách hàng đã chọn không tham gia. Chúng cũng giúp người dùng dữ liệu có thể hiểu được bảng dữ liệu nào chứa PII bằng cách tự động phát hiện và gắn thẻ các cột trong danh mục dữ liệu bằng AWS Glue’s PII detection algorithm.\nGiá trị của việc xử lý các dữ liệu thời gian thực Khi bạn xử lý dữ liệu càng nhanh và sớm sau khi dữ liệu được tạo, quyết định sẽ được đưa ra nhanh hơn và chính xác hơn Các thiết kế mẫu trong phân tích dữ liệu streaming, được thực hiện bằng cách sử dụng các dịch vụ như Amazon Managed Streaming for Apache Kafka (Amazon MSK) hoặc Amazon Kinesis, tạo ra một enterprise eventbus để trao đổi dữ liệu giữa các ứng dụng không đồng nhất trong thời gian thực.\nVí dụ: người ta thường sử dụng tính năng streaming để tăng cường quá trình thu thập dữ liệu (data ingestion) từ CSDL truyền thống bằng phương pháp CDC vào data lake cùng với quá trình streaming ingestion bổ sung cho các application events. CDC là một mẫu thiết kế kiến trúc thu thập dữ liệu phổ biến, nhưng thông tin có thể ở mức quá chi tiết. Điều này yêu cầu bối cảnh ứng dụng phải được tái tạo lại trong data lake và business logic phải được sử giống giống nhau ở hai nơi, bên trong ứng dụng và trong lớp xử lý data lake. Điều này tạo ra nguy cơ trình bày sai ngữ nghĩa của ngữ cảnh ứng dụng.\nZendesk đã phải đối mặt với thách thức này khi thực hiện CDC data lake ingestion của họ từ các Aurora clusters. Họ đã tạo một event bus được xây dựng với Apache Kafka để tăng cường CDC của họ với các application domain events cấp cao hơn để trao đổi trực tiếp giữa các ứng dụng không đồng nhất.\nKiến trúc streaming của Zendesk CDC database ticket table schema đôi khi có thể chứa các thuộc tính phức tạp và không cần thiết dành riêng cho ứng dụng và không thể hiện được domain model của ticket. Điều này khiến cho downstream consumers không hiểu để sử dụng dữ liệu. Một ticket domain object có thể bao gồm một số database tables khi được modeled ở dạng third normal form, điều này làm cho việc truy vấn đối với các nhà phân tích trở nên khó khăn. Đây cũng là một phương pháp tích hợp dễ gây ra vấn đề vì các ứng dụng và dịch vụ sử dụng dữ liệu có thể dễ dàng bị ảnh hưởng khi logic của ứng dụng thay đổi, điều này khiến cho việc thiết lập một chế độ xem dữ liệu chung trở nên khó khăn.\nĐể hướng tới giao tiếp dựa trên sự kiện giữa các microservices, Zendesk đã tạo dự án Platform Data Architecture (PDA), sử dụng standard object model để thể hiện chế độ xem ngữ nghĩa, cấp cao hơn của dữ liệu ứng dụng của họ. Standard objects là các domain objects được thiết kế để giao tiếp giữa nhiều domain và không chịu ảnh hưởng bởi cơ chế CDC. Cuối cùng, Zendesk đặt mục tiêu chuyển đổi data architecture của họ từ một tập hợp các isolated products và data silos thành một nền tảng dữ liệu thống nhất gắn kết.\n Hình 2. Một góc nhìn ứng dụng của kiến trúc streaming Zendesk.   Hình 2 cho thấy cách tất cả các sản phẩm và người dùng của Zendesk tích hợp thông qua các standard objects chung và các standard events trong Data Hub. Các ứng dụng publish và sử dụng ( consume ) standard objects và events đều đến từ event bus.\nVí dụ, một complete ticket standard object sẽ được xuất bản lên eventbus bất cứ khi nào nó được tạo, cập nhật hoặc thay đổi. Về mặt sử dụng ( consume ), các sự kiện này được nhóm sản phẩm sử dụng để kích hoạt các khả năng của nền tảng như tìm kiếm, xuất dữ liệu, phân tích và trang tổng quan báo cáo.\nTóm lược Khi hoạt động kinh doanh của Zendesk phát triển, data lake của họ đã phát triển từ các tệp Parquet đơn giản trên Amazon S3 thành data lake và có thể cập nhật tăng dần dựa trên kiến trúc Hudi hiện đại. Giờ đây, các chính sách bảo mật IAM của họ được sử dụng nhằm kiểm soát truy cập chi tiết thông qua Lake Formation.\nChúng tôi đã nhiều lần chứng kiến những cải tiến về mặt kiến trúc một cách từ từ đạt được thành công vì nó làm giảm rủi ro kinh doanh liên quan đến sự thay đổi và cung cấp đủ thời gian cho nhóm của bạn để tìm hiểu và đánh giá các hoạt động và các dịch vụ được quản lý trên Cloud.\nNếu bạn muốn tìm kiếm thêm nội dung về kiến trúc? AWS Architecture Center cung cấp các sơ đồ kiến trúc tham chiếu, các giải pháp kiến trúc đã được hiệu chỉnh, các phương pháp hay nhất Well-Architected, các mẫu, biểu tượng và hơn thế nữa!\nCác bài viết khác trong loạt bài này  Insights for CTOs: Part 1 – Building and Operating Cloud Applications Insights for CTOs: Part 2 – Enable Good Decisions at Scale with Robust Security  "
},
{
	"uri": "/vi/2-windowsonaws/2.1-blog-1/",
	"title": "Khởi chạy Microsoft Windows Server instances trên Amazon EC2 nhanh hơn tới 65% so với trước đây",
	"tags": [],
	"description": "",
	"content": "GIỚI THIỆU Khách hàng của AWS khi chạy Microsoft Windows Server instances phải đối mặt với việc thời gian chờ đợi lâu trong khi chờ cấp phép instances, vì Windows Server Operating System (OS) trải qua một quá trình khởi động kéo dài.\n Đối với các nhà phát triển và chuyên gia CNTT, điều này sẽ gây khó khăn cho việc deployment và đảm bảo SLAs của hệ thống dịch vụ (Service Level Agreements – viết tắt là SLAs). Khi cần sử dụng SLAs ở mức độ cao với khối lượng công việc quan trọng nhiều, các chuyên gia CNTT thường yêu cầu cung cấp tài nguyên nhanh hơn, đồng thời tránh vượt quá chi phí. Việc cung cấp tài nguyên nhanh hơn và đáng tin cậy hơn có thể đáp ứng các yêu cầu khắt khe về thời gian của các ứng dụng và dịch vụ quan trọng trong việc mở rộng quy mô hoặc phục hồi hệ thống.  AWS đã công bố chức năng mới đó là khởi tạo mày chủ Amazon Elastic Compute Cloud (Amazon EC2) chạy Microsoft Windows Server OS với tốc độ nhanh hơn 65% so với trước đây. Khách hàng có thể sử dụng chức năng này cho cả các stock AMIs (được quản lý bởi AWS) và custom Amazon Machine Images (AMIs).\n Đối với custom AMIs, thời gian khởi chạy giảm xuống còn khoảng 85 giây so với thông thường là 242 giây và đối với stock AMIs, thời gian khởi chạy đạt được khoảng 45 giây. Bằng cách khởi chạy Windows instances nhanh hơn, tính năng mới giúp cung cấp kịp thời instances trên quy mô lớn, SLAs sẽ được cải thiện trong việc hỗ trợ các yêu cầu triển khai tăng đột biến và phản hồi nhanh hơn trong việc đáp ứng các yêu cầu khôi phục dịch vụ hoặc các yêu cầu về chuyển đổi sang hệ thống chờ. ( fail-over)  Trong bài đăng trên blog này, chúng tôi sẽ giới thiệu cho bạn một số trường hợp sử dụng cho chức năng khởi chạy nhanh hơn này và cung cấp quy trình chi tiết từng bước để kích hoạt nó trên AMIs của bạn thông qua bản điều khiển Amazon EC2 hoặc AWS Command Line Interface (CLI) hoặc Application Programming Interface (API).\nUSE CASES Việc khởi chạy nhanh các custom Windows AMIs giúp đáp ứng yêu cầu đối với các trường hợp nhạy cảm về thời gian hoặc nhu cầu cao, nơi thời gian khởi chạy là yếu tố quan trọng để thành công. Các phần mềm custom Windows AMIs thường chạy, chẳng hạn như Microsoft SharePoint, Microsoft Dynamics CRM, Microsoft Active Directory hoặc một ứng dụng NET-based custom được triển khai trên Windows Server hoặc trên Microsoft Internet Information Server (IIS). Sau đây là một số trường hợp sử dụng mà tinh năng khởi chạy nhanh hơn cho các AMI tuỳ chỉnh có thể được tận dụng.\nSCALABLE DEPLOYMENT Việc triển khai khối lượng công việc có thể mở rộng giúp đáp ứng nhu cầu tài nguyên luôn biến động và tối ưu hóa hiệu suất chi phí on-demand, sử dụng tối ưu tài nguyên. Một trong những trường hợp sử dụng là phục vụ những sự kiện cần thời gian triển khai nhanh , với qui mô lớn, chẳng hạn dịch chuyển ứng dụng với qui mô lớn, các sự kiện xã hội hoặc công ty, bầu cử của một quốc gia,….. Một trường hợp sử dụng khác là nó giúp chúng ta xử lý hàng loạt công việc như là để xử lý dữ liệu hàng ngày, hàng tuần hoặc xử lý hàng tháng đối với quá trình nhập, lọc và quản lý dữ liệu. Mở rộng kịp thời custom Windows AMI-based EC2 là rất quan trọng cho sự thành công của các sự kiện này. Tính năng khởi chạy nhanh hơn của Windows giúp mở rộng quy mô khi khởi chạy instance EC2 nhanh hơn.\nDISASTER RECOVERY (DR) Khách hàng có thể triển khai kế hoạch khôi phục sau thảm họa trong các cấu hình sao lưu và khôi phục, Pilot Light hoặc Warm Standby configurations. Khách hàng có thể triển khai khi sử dụng custom Windows AMIs với Microsoft stack of software, such as SharePoint, Dynamics CRM, etc. Với việc khởi chạy nhanh các instance EC2 tại trang DR là điều quan trọng để đáp ứng Recovery Time Objective (viết tắt là RTO). Tính năng khởi chạy nhanh hơn của Windows giúp đáp ứng yêu cầu RTO cho chiến lược triển khai.\nFAILOVER Nhiều phần mềm của bên thứ 3 hoặc các giải pháp đối tác AWS sử dụng cơ chế phân cụm chủ động-thụ động để giải quyết yêu cầu chuyển lỗi. Khi (các) cá thể EC2 chủ động không khả dụng, (các) cá thể EC2 thụ động sẽ tiếp quản và trở nên hoạt động. Hầu hết các cấu hình này sử dụng Windows AMI tùy chỉnh chạy phần mềm Microsoft hoặc các giải pháp đối tác AWS sử dụng phần mềm của Microsoft. Khôi phục nhanh hơn (các) instance EC2 thụ động giúp dịch vụ tiếp tục hoạt động. Tính năng khởi chạy nhanh của Windows đẩy nhanh thời gian phục hồi trạng thái hoạt động của cluster dịch vụ.\nTÓM TẮT TÍNH NĂNG Khởi chạy Windows nhanh hơn khả dụng cho cả stock AMIs (AWS tối ưu hóa trước 20 hình ảnh phổ biến nhất do Amazon quản lý) và custom Windows AMIs.\n Đối với stock AMIs, nó có sẵn ngay từ đầu và đối với custom AMIs, cần phải có cấu hình tối ưu hóa image. Custom AMIs được định cấu hình để tối ưu hóa image bằng AWS Management Console, AWS CLI, API, hoặc Amazon EC2 Image Builder. Khi có ý định cấu hình custom AMIs để tối ưu hóa image , bạn cần chọn Enable Windows faster launching và cũng cần chỉ định anticipated image launch frequency. Anticipated image launch frequency được sử dụng để chỉ định số lượng instance EC2 mà bạn muốn khởi chạy trong một giờ. - Tần suất khởi chạy có thể được chọn từ tần suất xác định trước, chẳng hạn như low – 5 launches per hour hoặc cũng có thể được xác định dưới dạng custom value, chẳng hạn như 50 launches per hour. (Giới hạn lý thuyết cho tham số là 200.000, nhưng đối với tất cả các mục đích thực tế, lời khuyên là không nên thử tham số này). Pre-provisioned snapshots được cấp phép trước, chúng được sử dụng để làm giảm thời gian khởi chạy EC2 Windows Instance khi được tối ưu hóa sử dụng Windows AMIs. Amazon EC2 khởi chạy một instance sử dụng Windows AMIs để tạo pre-provisioned snapshots được cấp phép trước. Nó hoàn thành các bước như Sysprep specialize, Windows Out of Box Experience (OOBE) và khởi động lại theo yêu cầu. Cuối cùng, nó dừng instance và tạo snapshot, sau đó được sử dụng cho các lần khởi chạy tiếp theo, làm cho các lần khởi chạy nhanh hơn. Dựa trên cấu hình tần suất khởi chạy, các snapshot dự trữ sẽ tự động bổ sung khi được sử dụng hết. Bạn có thể tăng tần suất khởi chạy trước để giải quyết nhu cầu về số lượng instance tăng đột biến để xử lý bất kỳ sự kiện đặc biệt nào. Tần số khởi chạy có thể được đặt lại khi các yêu cầu trở lại bình thường.  KHỞI ĐỘNG TÍNH NĂNG Vui lòng xem lại phần chuẩn bị trước khi bật tính năng này và vui lòng lưu ý rằng Windows AMIs phải được tạo bằng Sysprep với tùy chọn tắt máy để chọn tính năng khởi chạy nhanh hơn này trên AMIs.\n Đối với các phác thảo demo trong bài đăng blog này, có hai Windows custom AMIs được tạo bằng cách sử dụng các instance Sysprep Windows EC2 (xem Hình 1).   Hình 1. EC2 Instances    Một AMIs bao gồm Microsoft Active Directory được cấu hình sẵn, trong khi AMIs kia bao gồm Microsoft SQL Server được cấu hình trước (xem Hình 2)   Hình 2. Custom AMIs    Cả hai đều được cấu hình bằng ổ đĩa gốc mặc định.  Để sử dụng các AMIs này, các phần sau mô tả cách bật tính năng khởi chạy nhanh hơn của Windows bằng AWS Management Console and CLI.\nSỬ DỤNG AWS MANAGEMENT CONSOLE Làm theo các bước sau để bật tính năng khởi chạy Windows nhanh hơn này trong AWS Management Console.\n Mở bảng điều khiển Amazon EC2 tại EC2 Dashboard. Trong khung điều hướng, bên dưới Image, chọn AMIs (xem Hình 3).   Hình 3. EC2 Console AMI Menu Option   Chọn AMIs mà bạn muốn bật tính năng (xem Hình 4).   Hình 4. Select the Custom AMI   Từ menu Actions, chọn Manage image optimization (xem Hình 5). Thao tác này sẽ mở ra trang Manage image optimizations , nơi bạn có thể định cấu hình cài đặt để khởi chạy nhanh hơn.   Hình 5. Image Optimization Option   Chọn Enable Windows faster launching.(xem Hình 6).   Hình 6. Windows Faster Launching Configuration   Từ danh sách thả xuống Set anticipated launch frequency, hãy chọn một giá trị để chỉ định số lượng snapshot sẽ được tạo và duy trì để bao gồm khối lượng khởi chạy instance dự kiến của bạn. Đối với phần demo này , tôi đã chọn Low-5 launches per hour (xem Hình 7).   Hình 7. Image Launch Frequency Configuration   Chọn nút Save Changes để bật tính năng này khi bạn hoàn tất cấu hình.   Khi bạn kích hoạt tính năng này, một số cấu hình và tự động hóa sẽ xảy ra ngầm mà bạn cần biết. Một số instance EC2 được khởi chạy theo cấu hình tần số khởi chạy. Các instance EC2 này được sử dụng để tạo snapshot cho việc khởi chạy nhanh. Các instance EC2 này tự động kết thúc khi các snapshot được tạo và sẵn sàng (xem Hình 8).   Hình 8. EC2 Instances Launched for Snapshots   Launch Template mặc định được tạo trong các Launch Template, được kiểm soát theo instance. Launch Templates chỉ định loại instance sẽ được khởi chạy.   Hình 9. Launch Template   Một IAM role liên kết dịch vụ AWS Service RoleForEC2FastLaunch được tạo (xem Hình 10.). Tham khảo IAM role liên kết dịch vụ để tìm hiểu thêm.   Hình 10. Service Linked Role   Trong Snapshots, bạn có thể xem các snapshot đã được tạo cho các images (xem Hình 11). Những snapshot này được sử dụng cho các lần khởi chạy tiếp theo.   Hình 11. The Snapshots   KHÁM PHÁ TÍNH NĂNG THÔNG QUA AWS MANAGEMENT CONSOLE Bỏ chọn hộp kiểm Enable Windows faster launching để dừng khởi chạy nhanh hơn đối với các instance Windows EC2 và để loại bỏ các snapshot được khởi tạo trước (xem Hình 6). Sau đó, AMI sẽ sử dụng quy trình khởi chạy tiêu chuẩn cho từng instance về sau.\nVui lòng tham khảo tài liệu Windows Fast Launch Config để biết thêm thông tin và tùy chọn. Trong phần này, chúng tôi đã trình bày các bước để định cấu hình tính năng khởi chạy nhanh hơn của Windows bằng Bảng điều khiển quản lý AWS. Trong phần tiếp theo, chúng tôi sẽ định cấu hình tính năng bằng AWS CLI.\nSỬ DỤNG AWS CLI Sau đây là các bước để bật tính năng khởi chạy Windows nhanh hơn bằng AWS CLI. Hãy đảm bảo thực hiện sysprep instance Windows EC2 trước khi bật tính năng này.\nLưu ý: Hãy đảm bảo rằng bạn đang chạy instance CLI mới nhất (at least 2.4.15) để lệnh bật-khởi chạy nhanh hiển thị. Bạn cũng có thể sử dụng CloudShell từ bảng điều khiển để làm điều tương tự. Chạy lệnh AWS CLI sau để bật tính năng khởi chạy nhanh hơn của Windows cho AMI. Trong ví dụ này, ID của AMI là ami-07d3ee0bb1b8e8614 (xem Hình 12)\naws ec2 enable-fast-launch --image-id ami-07d3ee0bb1b8e8614 --snapshot-configuration TargetResourceCount=10\r--resource-type snapshot  Hình 12. AWS CLI for Faster Launch   Vui lòng tham khảo tài liệu Enable-fast-launch và Disable-fast-launch để biết thêm chi tiết.\nDỰ KIẾN CHI PHÍ DỊCH VỤ   Không có phí dịch vụ bổ sung khi sử dụng chức năng khởi chạy nhanh hơn. Chỉ các tài nguyên AWS cơ bản đang chạy trong Tài khoản khách hàng như một phần của dịch vụ mới được tính vào chi phí sử dụng.\n  Để minh họa, chúng ta hãy xem xét kịch bản cho phép khởi chạy nhanh hơn với cài đặt tần suất mặc định là 5 lần khởi chạy mỗi giờ. Dịch vụ khởi chạy trước 5 instance T trong nền, sử dụng Windows Server OS thông qua các giai đoạn Sysprep trong quá trình khởi động. Bước này mất khoảng 15 phút (điều này thay đổi tùy thuộc vào mức độ quá tải của vùng / khu vực và AMI lớn như thế nào).\n  Thời gian chạy của mỗi instance T và volume EBS đính kèm được tính vào chi phí sử dụng. Tiếp theo, dịch vụ snapshot sẽ tương ứng với từng instance và lưu trữ chúng. Việc lưu trữ 5 snapshot image trong S3 được lập hóa đơn. Mỗi snapshot image sẽ được sử dụng hết khi một instance được khởi chạy nhanh từ AMI. Vì vậy, chi phí lưu trữ S3 phụ thuộc vào thời lượng lưu trữ snapshot trước khi được sử dụng để khởi chạy nhanh từ AMI.\n  Thông thường, chúng ta thấy rằng một snapshot image tồn tại trong khoảng 4-8 giờ trước khi được sử dụng. Khi tất cả 5 snapshot image được sử dụng, dịch vụ sẽ tự động bổ sung chúng trong nền bằng cách chạy các instance T và tiến hành tạo các snapshots . Nếu dịch vụ được sử dụng trong cả tháng, tổng chi phí cho mỗi AMI sẽ vào khoảng $ 5,00 - $ 6,00 mỗi tháng cho AMI dung lượng 50 GB với cài đặt mặc định là 5 lần khởi chạy mỗi giờ. Các tính toán chi phí được cung cấp ở đây chỉ là ước tính và chi phí thực tế có thể thay đổi dựa trên việc sử dụng và các yếu tố khác.\n  KẾT LUẬN Trong bài đăng này, chúng tôi đã đề cập đến cách khách hàng có thể thiết lập những image cần thiết, nhạy cảm với thời gian - chẳng hạn như những image được sử dụng để mở rộng quy mô, khôi phục thảm họa hoặc chuyển hệ thống sang hệ thống chờ ( fail-over ) - để sẵn sàng khởi chạy nhanh với cấu hình tính năng đơn giản. Cấu hình được bật trong phần Quản lý AMI của Bảng điều khiển Amazon EC2 thông qua lệnh API / CLI hoặc trong Image Builder. Tìm hiểu thêm từ thông báo What’s New và documentation để khởi chạy các instance Windows nhanh hơn.\nAWS có thể giúp bạn đánh giá cách công ty của bạn có thể tận dụng tối đa các giá trị mà nền tảng điện toán đám mây mang lại. Tham gia cùng hàng triệu khách hàng AWS tin tưởng chúng tôi để di chuyển và hiện đại hóa các ứng dụng quan trọng nhất của họ trên đám mây. Để tìm hiểu thêm về cách hiện đại hóa Windows Server hoặc SQL Server, hãy truy cập Windows on AWS. Liên hệ với chúng tôi để bắt đầu hành trình di chuyển của bạn ngay hôm nay.\n"
},
{
	"uri": "/vi/4-dataanalytics/4.1-blog-1/",
	"title": "Những điều cần quan tâm khi dịch chuyển Data warehouse lên Amazon Redshift",
	"tags": [],
	"description": "",
	"content": "Những điều cần quan tâm khi dịch chuyển Data warehouse lên Amazon Redshift Khách hàng đang dần chuyển kho dữ liệu (data warehouse) sang Amazon Redshift vì Amazon Redshift nhanh, có khả năng mở rộng và tiết kiệm chi phí. Tuy nhiên, các dự án di chuyển data warehouse có thể rất phức tạp và đầy thách thức. Trong bài viết này, tôi giúp bạn hiểu các yếu tố tác động phổ biến của việc dịch chuyển data warehouse, chiến lược dịch chuyển cũng như những công cụ và dịch vụ nào sẵn sàng để hỗ trợ dự án của bạn.\nTrước tiên, chúng ta hãy thảo luận về big data landscape, ý nghĩa của kiến trúc dữ liệu hiện đạivà những điều bạn cần xem xét đối với các dự án dịch chuyển data warehouse khi xây dựng kiến trúc dữ liệu hiện đại.\nCơ hội kinh doanh Dữ liệu đang thay đổi cách chúng ta làm việc, sống và vui chơi. Tất cả sự thay đổi hành vi này và sự dịch chuyển lên cloud đã dẫn đến sự bùng nổ dữ liệu trong 20 năm qua. Sự phát triển của Internet of Things (IoT) và điện thoại thông minh đã đẩy nhanh lượng dữ liệu được tạo ra mỗi ngày. Các mô hình kinh doanh đã thay đổi, và nhu cầu của những người điều hành các doanh nghiệp này cũng vậy. Chúng ta đã chuyển từ việc nói về hàng terabyte dữ liệu chỉ vài năm trước đây sang hàng petabyte và exabyte dữ liệu. Bằng cách đưa dữ liệu vào hoạt động một cách tối ưu và xây dựng thông tin (insight) chi tiết sâu sắc về kinh doanh từ dữ liệu thu thập được, các doanh nghiệp thuộc các ngành khác nhau và thuộc nhiều quy mô khác nhau có thể đạt được kết quả kinh doanh đa dạng. Các mục tiêu có thể được phân loại thành các kết quả kinh doanh cốt lõi sau:\n  Cải thiện độ tối ưu của quá trình vận hành - Bằng cách hiểu rõ dữ liệu được thu thập từ các quy trình hoạt động khác nhau, các doanh nghiệp có thể cải thiện trải nghiệm của khách hàng, tăng hiệu quả sản xuất và tăng khả năng bán hàng và tiếp thị.\n  Đưa ra quyết định sáng suốt hơn - Thông qua việc phát triển những hiểu biết sâu sắc và có ý nghĩa hơn bằng cách tập hợp bức tranh toàn cảnh về dữ liệu trong một tổ chức, các doanh nghiệp có thể đưa ra quyết định sáng suốt hơn\n  Tăng tốc đổi mới - Việc kết hợp các nguồn dữ liệu nội bộ và bên ngoài cho phép nhiều trường hợp sử dụng trí tuệ nhân tạo (Artificial Intelligence) và Máy học (Machine Learning) giúp các doanh nghiệp tự động hóa các quy trình và mở ra các cơ hội kinh doanh mà trước đây không thể làm được hoặc quá khó thực hiện\n  Thách thức trong doanh nghiệp Tăng trưởng dữ liệu theo cấp số nhân cũng đã tạo ra những thách thức lớn trong kinh doanh.\nTrước hết, các doanh nghiệp cần truy cập tất cả dữ liệu trong toàn tổ chức và dữ liệu có thể được phân chia thành các silos. Các dữ liệu đến từ nhiều nguồn khác nhau, trong một loạt các loại dữ liệu với khối lượng và tốc độ lớn. Một số dữ liệu có thể được lưu trữ dưới dạng dữ liệu có cấu trúc trong cơ sở dữ liệu quan hệ. Các dữ liệu khác có thể được lưu trữ dưới dạng dữ liệu bán cấu trúc trong các object stores, chẳng hạn như media files và dữ liệu clickstream data, chúng liên tục được truyền trực tuyến từ các thiết bị di động.\nThứ hai, để xây dựng thông tin chi tiết từ dữ liệu, doanh nghiệp cần đi sâu vào dữ liệu bằng cách tiến hành phân tích. Các hoạt động phân tích yêu cầu một lượng lớn nhà phân tích dữ liệu, đến hàng chục và hàng trăm người, những người này cần truy cập hệ thống đồng thời với nhau. Để sở hữu một hệ thống hiệu suất có khả năng mở rộng để đáp ứng nhu cầu truy vấn thường là một thách thức lớn. Nó càng trở nên phức tạp hơn khi các doanh nghiệp cần chia sẻ dữ liệu đã phân tích với khách hàng của họ.\nCuối cùng nhưng không kém phần quan trọng, các doanh nghiệp cần một giải pháp hiệu quả về chi phí để giải quyết vấn đề dữ liệu bị silo, hiệu suất, khả năng mở rộng, bảo mật và tuân thủ. Việc có thể hình dung và dự đoán chi phí là cần thiết đối với một doanh nghiệp để đo lường hiệu quả chi phí của giải pháp của mình.\nĐể giải quyết những thách thức này, các doanh nghiệp cần một kiến ​​trúc dữ liệu hiện đại trong tương lai và một hệ thống phân tích mạnh mẽ, hiệu quả.\nKiến trúc dữ liệu hiện đại Modern data architecture (Kiến trúc dữ liệu hiện tại) cho phép các tổ chức lưu trữ bất kỳ lượng dữ liệu nào ở các open formats, hạn chế việc tồn tại các silos về dữ liệu, trao quyền cho người dùng chạy các thao tác phân tích hoặc Máy học (Machine Learning) bằng cách sử dụng công cụ hoặc kỹ thuật ưa thích của họ và quản lý những người có quyền truy cập vào các phần dữ liệu cụ thể với bảo mật phù hợp và các biện pháp kiểm soát quản trị dữ liệu.\nAWS data lake architecture (Kiến trúc hồ dữ liệu) là một kiến trúc dữ liệu hiện đại cho phép bạn lưu trữ dữ liệu trong data lake và sử dụng một vòng tròn các dịch vụ dữ liệu và chúng được xây dựng có mục đích xung quanh data lake, như được minh họa trong hình sau. Điều này cho phép bạn đưa ra quyết định nhanh chóng trên quy mô lớn và hiệu quả về chi phí. Để biết thêm chi tiết, hãy tham khảo Modern Data Architecture on AWS.\n Kiến trúc dữ liệu hiện đại   Kho dữ liệu hiện đại Amazon Redshift là modern data warehouse ( kho dữ liệu hiện đại ) được quản lý hoàn toàn, có thể mở rộng, giúp tăng tốc thời gian tìm hiểu thông tin chi tiết (insights) với khả năng phân tích nhanh chóng, dễ dàng và an toàn trên quy mô lớn. Với Amazon Redshift, bạn có thể phân tích tất cả dữ liệu của mình và nhận được hiệu suất ở bất kỳ quy mô nào với chi phí thấp và có khả năng dự đoán cao.\n Kho dữ liệu hiện đại   Amazon Redshift đem lại những lợi ích sau:\n  Phân tích mọi dữ liệu - Với Amazon Redshift, bạn có thể dễ dàng phân tích tất cả dữ liệu của mình trên data warehouse và data lake với các chính sách quản trị và bảo mật nhất quán. Chúng tôi gọi đây là modern data architecture. Với Amazon Redshift Spectrum, bạn có thể truy vấn dữ liệu trong data lake của mình mà không cần đưa dữ liệu vào Redshift cluster hoặc chuẩn bị dữ liệu. Và với tính năng data lake export, bạn có thể lưu kết quả của truy vấn Amazon Redshift trở lại data lake. Điều này có nghĩa là bạn có thể tận dụng các phân tích thời gian thực và các trường hợp sử dụng Machine Learning / Artificial intelligence mà không cần tái kiến ​​trúc, vì Amazon Redshift được tích hợp hoàn toàn với data lake của bạn. Với các tính năng mới như data sharing, bạn có thể dễ dàng chia sẻ dữ liệu trên các Amazon Redshift cluster cả bên trong và bên ngoài, để mọi người có cái nhìn trực tiếp và nhất quán về dữ liệu. Amazon Redshift ML giúp bạn dễ dàng làm được nhiều việc hơn với dữ liệu của mình — bạn có thể tạo, đào tạo ( train ) và triển khai các mô hình Machine Learning bằng cách sử dụng các lệnh SQL quen thuộc trực tiếp trong Amazon Redshift data warehouses.\n  Hiệu suất nhanh cho mọi quy mô - Amazon Redshift là một hệ thống có khả năng tự điều chỉnh và tự học cho phép bạn đạt được hiệu suất tốt nhất cho khối lượng công việc của mình mà không cần phải điều chỉnh data warehouse của bạn với các tác vụ như xác định sort keys và distribution keys, và các khả năng mới như materialized views, auto-refresh, and auto-query rewrite. Amazon Redshift mở rộng quy mô để cung cấp kết quả nhanh chóng nhất quán từ gigabyte đến petabyte dữ liệu và từ một vài người dùng đến hàng nghìn người. Khi cơ sở người dùng của bạn mở rộng đến hàng nghìn người dùng đồng thời, khả năng mở rộng concurrency scaling sẽ tự động triển khai các tài nguyên tính toán cần thiết để quản lý tải bổ sung. Amazon Redshift RA3 instances với tài nguyên tính toán và lưu trữ riêng biệt được quản lý bởi AWS, vì vậy bạn có thể mở rộng quy mô một cách độc lập và chỉ trả tiền cho vùng lưu trữ bạn cần. AQUA (Advanced Query Accelerator) for Amazon Redshift là một bộ đệm phân tán mới và giúp tăng tốc phần cứng, tự động tăng hiệu năng cho một số loại truy vấn nhất định.\n  Phân tích dễ dàng cho mọi người - Amazon Redshift là một kho dữ liệu được quản lý hoàn toàn giúp loại bỏ gánh nặng quản lý cơ sở hạ tầng và tối ưu hóa hiệu suất. Bạn có thể tập trung vào việc tìm hiểu insight, thay vì thực hiện các tác vụ bảo trì như cung cấp cơ sở hạ tầng, tạo bản sao lưu, thiết lập bố cục dữ liệu và các tác vụ khác. Bạn có thể vận hành dữ liệu ở các định dạng mở, sử dụng các lệnh SQL quen thuộc và tận dụng trực quan hóa truy vấn có sẵn thông qua Query Editor v2 mới. Bạn cũng có thể truy cập dữ liệu từ bất kỳ ứng dụng nào thông qua API dữ liệu an toàn mà không cần cấu hình trình điều khiển phần mềm, quản lý kết nối cơ sở dữ liệu. Amazon Redshift tương thích với các công cụ business intelligence (BI), mở ra sức mạnh và khả năng tích hợp của Amazon Redshift cho người dùng doanh nghiệp hoạt động từ bên trong công cụ BI.\n  Kiến trúc dữ liệu hiện đại , kiến trúc data lake và kho dữ liệu hiện đại với Amazon Redshift giúp các doanh nghiệp ở mọi quy mô khác nhau giải quyết những thách thức về dữ liệu lớn, hiểu được lượng lớn dữ liệu và thúc đẩy kết quả kinh doanh. Bạn hãy bắt đầu hành trình xây dựng kiến trúc dữ liệu hiện đại bằng cách di chuyển kho dữ liệu của mình sang Amazon Redshift.\nCác vấn đề cần quan tâm khi dịch chuyển Bạn có thể chọn một trong số ba chiến lược dịch chuyển sau: one-step migration, two-step migration, hoặc wave-based migration.\nOne-step migration là một lựa chọn tốt cho các cơ sở dữ liệu không yêu cầu hoạt động liên tục, chẳng hạn như sao chép liên tục để giữ cho các thay đổi dữ liệu đang diễn ra đồng bộ giữa nguồn và đích. Bạn có thể trích xuất cơ sở dữ liệu hiện có dưới dạng file Comma Separated Value (CSV) hoặc columnar format như Parquet, sau đó sử dụng các dịch vụ AWS Snow Family chẳng hạn như AWS Snowball để cung cấp bộ dữ liệu tới Amazon Simple Storage Service (Amazon S3) để tải vào Amazon Redshift. Sau đó, bạn có thể kiểm tra cơ sở dữ liệu đích đến Amazon Redshift có nhất quán với dữ liệu nguồn hay không. Sau khi tất cả các xác thực đã được thông qua, cơ sở dữ liệu được chuyển sang AWS.\nTwo-step migrations thường được sử dụng cho cơ sở dữ liệu ở bất kỳ kích thước nào với yêu cầu hoạt động liên tục, chẳng hạn như sao chép liên tục. Trong quá trình dịch chuyển, cơ sở dữ liệu nguồn có các thay đổi dữ liệu liên tục và việc sao chép liên tục giúp các thay đổi dữ liệu được đồng bộ hóa giữa nguồn và Amazon Redshift. Bản phân tích của chiến lược di chuyển hai bước như sau:\n  Di chuyển dữ liệu ban đầu - Dữ liệu được trích xuất từ cơ sở dữ liệu nguồn, tốt nhất là nên sử dụng trong khoản thời gian không phải là giờ cao điểm để giảm thiểu tác động. Sau đó, dữ liệu được di chuyển sang Amazon Redshift bằng cách thực hiện theo phương pháp one-step migration được mô tả trước đây.\n  Di chuyển dữ liệu đã thay đổi - Dữ liệu đã thay đổi trong cơ sở dữ liệu nguồn sau khi di chuyển dữ liệu ban đầu được truyền đến đích trước khi chuyển đổi. Bước này đồng bộ hóa cơ sở dữ liệu nguồn và cơ sở dữ liệu đích. Sau khi tất cả dữ liệu đã thay đổi được di chuyển, bạn có thể xác thực dữ liệu trong cơ sở dữ liệu đích và thực hiện các kiểm tra cần thiết. Nếu tất cả các bài kiểm tra đều vượt qua, thì bạn chuyển sang kho dữ liệu Amazon Redshift.\n  Wave-based migration phù hợp với các dự án di chuyển kho dữ liệu quy mô lớn. Nguyên tắc của wave-based migration là thực hiện các biện pháp phòng ngừa để chia một dự án phức tạp thành nhiều wave hợp lý và có hệ thống. Chiến lược này có thể làm giảm đáng kể sự phức tạp và rủi ro. Bạn bắt đầu từ một workload bao gồm nhiều nguồn dữ liệu và lĩnh vực chủ đề có độ phức tạp trung bình, sau đó thêm nhiều nguồn dữ liệu và lĩnh vực chủ đề hơn trong mỗi wave tiếp theo. Với chiến lược này, bạn chạy song song cả kho dữ liệu nguồn và môi trường Amazon Redshift Production trong một khoảng thời gian nhất định trước khi có thể ngừng hoạt động hoàn toàn kho dữ liệu nguồn. Xem phần Develop an application migration methodology to modernize your data warehouse with Amazon Redshift để biết chi tiết về cách xác định và nhóm các nguồn dữ liệu cũng như các ứng dụng phân tích để di chuyển từ kho dữ liệu nguồn sang Amazon Redshift bằng cách sử dụng phương pháp Wave-based migration.\nĐể quyết định chiến lược migration của bạn, hãy tham khảo bảng sau để lập bản đồ các yếu tố cần cân nhắc với chiến lược migration ưu tiên.\n    One-Step Migration Two-Step Migration Wave-Based Migration     Số lượng các lĩnh vực trong phạm vi của project dịch chuyển dữ liệu Nhỏ Vừa tới Lớn Vừa tới lớn   Dung lượng dữ liệu cần dịch chuyển Nhỏ tới Lớn Nhỏ tới Lớn Nhỏ tới Lớn   Tần suất dữ liệu thay đổi trong quá trình dịch chuyển Không thay đổi Ít tới Thường xuyên Ít tới Thường xuyên   Tính phức tạp của việc chuyển đổi dữ liệu Bất kỳ Bất kỳ Bất kỳ   Thời gian thực hiện chuyển đổi từ nguồn sang đích Vài giờ Vài giây Vài giây   Thời gian cho dự án dịch chuyển Vài tuần Vài tuần tới vài tháng Vài tháng    Quá trình di chuyển Trong phần này, chúng tôi xem xét các bước tổng quan của quá trình dịch chuyển. Chiến lược two-step migration và chiến lược wave-based migration bao gồm cả ba bước migration. Tuy nhiên, chiến lược wave-based migration bao gồm một số lần lặp lại. Những cơ sở dữ liệu không yêu cầu hoạt động liên tục mới phù hợp cho quá trình one-step migration, chỉ cần có Bước 1 và 2 trong quy trình migration.\nBước 1: Chuyển đổi schema theo từng lĩnh vực Trong bước này, bạn hãy làm cho source data warehouse schema nguồn tương thích với Amazon Redshift schema bằng cách chuyển đổi source data warehouse schema, để làm được điều đó, bạn sử dụng các schema conversion tools như AWS Schema Conversion Tool (AWS SCT) và các công cụ khác từ các đối tác của AWS. Trong một số tình huống, bạn cũng có thể được yêu cầu sử dụng mã tùy chỉnh để thực hiện các chuyển đổi schema phức tạp. Chúng ta tìm hiểu sâu hơn về AWS SCT và các phương pháp di chuyển tốt nhất trong phần sau.\n Chuyển đổi schema theo từng lĩnh vực   Bước 2: Trích xuất dữ liệu ban đầu và load vào Amazon Redshift Trong bước này, bạn sẽ hoàn thành việc trích xuất dữ liệu ban đầu và load dữ liệu nguồn vào Amazon Redshift lần đầu tiên. Bạn có thể sử dụng AWS SCT data extractors để trích xuất dữ liệu từ source data warehouse và load dữ liệu lên Amazon S3 nếu kích thước dữ liệu và yêu cầu truyền dữ liệu của bạn cho phép bạn truyền dữ liệu qua mạng được kết nối. Ngoài ra, nếu có các giới hạn như giới hạn dung lượng mạng, bạn có thể load dữ liệu vào Snowball và từ đó dữ liệu được load lên Amazon S3. Khi dữ liệu trong kho dữ liệu nguồn có sẵn trên Amazon S3, dữ liệu đó sẽ được load vào Amazon Redshift. Trong các tình huống khi công cụ gốc của source data warehouse thực hiện công việc trích xuất và load dữ liệu tốt hơn so với trình trích xuất dữ liệu AWS SCT, bạn có thể chọn sử dụng các công cụ gốc để hoàn thành bước này.\n Trích xuất dữ liệu ban đầu và load vào Amazon Redshift   Bước 3: Delta và incremental load Trong bước này, bạn sử dụng AWS SCT và đôi khi là các công cụ gốc dành riêng cho source data warehouse để nắm bắt và load các thay đổi delta hoặc incremental từ các nguồn vào Amazon Redshift. Điều này thường được gọi là change data capture (CDC). CDC là một quá trình ghi lại những thay đổi được thực hiện trong cơ sở dữ liệu và đảm bảo rằng những thay đổi đó được sao chép tới một đích như data warehouse.\n Delta và incremental load   Bây giờ bạn sẽ có đủ thông tin để bắt đầu phát triển kế hoạch dịch chuyển cho data warehouse của mình. Trong phần sau, tôi đi sâu hơn vào các dịch vụ AWS có thể giúp bạn di chuyển data warehouse của mình sang Amazon Redshift và các phương pháp hay nhất khi sử dụng các dịch vụ này để đẩy nhanh quá trình triển khai dự án dịch chuyển data warehouse của bạn.\nDịch vụ hỗ trợ dịch chuyển kho dữ liệu Di chuyển kho dữ liệu bao gồm một tập hợp các dịch vụ và công cụ để hỗ trợ quá trình di chuyển. Bạn bắt đầu với việc tạo báo cáo đánh giá dịch chuyển cơ sở dữ liệu và sau đó chuyển đổi schema nguồn để tương thích với Amazon Redshift bằng cách sử dụng AWS SCT. Để di chuyển dữ liệu, bạn có thể sử dụng công cụ trích xuất dữ liệu AWS SCT, công cụ này có tích hợp với AWS Data Migration Service (AWS DMS) để tạo và quản lý các tác vụ AWS DMS cũng như sắp xếp việc dịch chuyển dữ liệu.\nĐể chuyển dữ liệu nguồn qua mạng được kết nối giữa trung tâm dữ liệu nguồn và AWS, bạn có thể sử dụng AWS Storage Gateway, Amazon Kinesis Data Firehose, Direct Connect, AWS Transfer Family services, Amazon S3 Transfer Acceleration, và AWS DataSync. Đối với việc di chuyển kho dữ liệu liên quan đến một khối lượng lớn dữ liệu hoặc nếu có những hạn chế với dung lượng mạng được kết nối với nhau, bạn có thể truyền dữ liệu bằng cách sử dụng dịch vụ AWS Snow Family. Với cách tiếp cận này, bạn có thể sao chép dữ liệu vào thiết bị, gửi lại cho AWS và sao chép dữ liệu vào Amazon Redshift thông qua Amazon S3.\nAWS SCT là một dịch vụ cần thiết để đẩy nhanh quá trình dịch chuyển kho dữ liệu của bạn sang Amazon Redshift. Bây giờ, chúng ta hãy đi sâu hơn vào nó.\nDịch chuyển dữ liệu bằng AWS SCT AWS SCT tự động hóa phần lớn quy trình chuyển đổi data warehouse schema của bạn sang Amazon Redshift database schema. Vì source and target database engines có thể có nhiều tính năng và khả năng khác nhau, AWS SCT cố gắng tạo một schema tương đương trong cơ sở dữ liệu mục tiêu của bạn bất cứ khi nào có thể. Nếu không thể chuyển đổi trực tiếp, AWS SCT sẽ tạo báo cáo đánh giá dịch chuyển cơ sở dữ liệu để giúp bạn chuyển đổi schema của mình. Báo cáo đánh giá dịch chuyển cơ sở dữ liệu cung cấp thông tin quan trọng về việc chuyển đổi schema từ cơ sở dữ liệu nguồn sang cơ sở dữ liệu đích của bạn. Báo cáo tóm tắt tất cả các nhiệm vụ chuyển đổi schema và nêu chi tiết các mục hành động cho các đối tượng schema không thể chuyển đổi sang công cụ DB của cơ sở dữ liệu mục tiêu của bạn. Báo cáo cũng bao gồm các ước tính về công sức sẽ cần để viết mã tương đương trong cơ sở dữ liệu mục tiêu của bạn mà không thể được chuyển đổi tự động.\nTối ưu hoá lưu trữ là một trọng tâm của chuyển đổi kho dữ liệu. Khi sử dụng cơ sở dữ liệu Amazon Redshift của bạn làm nguồn và cơ sở dữ liệu Amazon Redshift thử nghiệm làm mục tiêu, AWS SCT đề xuất các sort keys và distribution keys để tối ưu hóa cơ sở dữ liệu của bạn.\nVới AWS SCT, bạn có thể chuyển đổi các data warehouse schemas sau sang Amazon Redshift:\n Amazon Redshift Azure Synapse Analytics (version 10) Greenplum Database (version 4.3 và mới hơn) Microsoft SQL Server (version 2008 và mới hơn) Netezza (version 7.0.3 và mới hơn) Oracle (version 10.2 và mới hơn) Snowflake (version 3) Teradata (version 13 và mới hơn) Vertica (version 7.2 và mới hơn)  Tại AWS, chúng tôi tiếp tục phát hành các tính năng và cải tiến mới để cải thiện sản phẩm của mình. Để biết các chuyển đổi được hỗ trợ mới nhất, hãy truy cập AWS SCT User Guide.\nDịch chuyển dữ liệu bằng công cụ trích xuất dữ liệu AWS SCT Bạn có thể sử dụng AWS SCT data extraction tool để trích xuất dữ liệu từ kho dữ liệu tại chỗ của mình và di chuyển dữ liệu đó sang Amazon Redshift. Chủ động trích xuất dữ liệu của bạn và tải dữ liệu lên Amazon S3 hoặc dịch vụ AWS Snowball Family để di chuyển quy mô lớn. Sau đó, bạn có thể sử dụng AWS SCT để sao chép dữ liệu sang Amazon Redshift. Amazon S3 là một dịch vụ lưu trữ và truy xuất. Để lưu trữ một đối tượng trong Amazon S3, bạn tiến hành upload file bạn muốn lưu trữ lên S3 bucket. Khi upload file lên, bạn có thể đặt quyền trên đối tượng và cả trên bất kỳ metadata nào.\nTrong quá trình dịch chuyển quy mô lớn liên quan đến việc upload dữ liệu lên dịch vụ AWS Snowball Family, bạn có thể sử dụng quy trình làm việc dựa trên trình hướng dẫn trong AWS SCT để tự động hóa quy trình mà trong đó công cụ trích xuất dữ liệu điều phối AWS DMS để thực hiện quá trình dịch chuyển.\nCác cân nhắc đối với các công cụ dịch chuyển dữ liệu lên Amazon Redshift Để cải thiện và đẩy nhanh quá trình dịch chuyển data warehouse sang Amazon Redshift, hãy xem xét các mẹo và phương pháp hay nhất sau đây. Danh sách này không phải là danh sách đầy đủ hoàn toàn. Đảm bảo rằng bạn hiểu rõ về kho dữ liệu của mình và xác định các phương pháp hay nhất mà bạn có thể sử dụng cho dự án dịch huyển của mình.\n Sử dụng AWS SCT để tạo báo cáo đánh giá dịch chuyển và công sức cho các tác vụ dịch chuyển. Tự động hóa dịch chuyển với AWS SCT nếu có thể. Kinh nghiệm từ khách hàng của chúng tôi cho thấy AWS SCT có thể tự động tạo phần lớn các tập lệnh DDL và SQL. Khi không thể chuyển đổi schema tự động, hãy sử dụng tập lệnh tùy chỉnh để chuyển đổi mã. Cài đặt các tác nhân trích xuất dữ liệu AWS SCT càng gần nguồn dữ liệu càng tốt để cải thiện độ tin cậy và hiệu suất dịch chuyển dữ liệu. Để cải thiện hiệu suất dịch chuyển dữ liệu, hãy định kích thước phù hợp của máy chủ ảo Amazon Elastic Compute Cloud (Amazon EC2) của bạn và các máy ảo tương đương mà tác nhân trích xuất dữ liệu được cài đặt trên đó. Định cấu hình nhiều agent trích xuất dữ liệu để chạy nhiều tác vụ song song nhằm cải thiện hiệu suất dịch chuyển dữ liệu bằng cách tối đa hóa việc sử dụng băng thông mạng hiện có. Điều chỉnh cấu hình bộ nhớ AWS SCT để cải thiện hiệu suất chuyển đổi schema. Sử dụng Amazon S3 để lưu trữ các đối tượng lớn như hình ảnh, PDF và dữ liệu nhị phân khác từ kho dữ liệu hiện có của bạn. Để dịch chuyển các bảng lớn, hãy sử dụng phân vùng ảo và tạo các tác vụ con để cải thiện hiệu suất dịch chuyển dữ liệu. Hiểu các trường hợp sử dụng của các dịch vụ AWS như AWS Direct Connect, AWS Transfer Family và Nhóm AWS Snow. Chọn dịch vụ hoặc công cụ phù hợp để đáp ứng các yêu cầu dịch chuyển dữ liệu của bạn. Hiểu quota của dịch vụ AWS và đưa ra quyết định thiết kế dịch chuyển phù hợp.  Tóm lược Dữ liệu đang phát triển về khối lượng và độ phức tạp nhanh hơn bao giờ hết. Tuy nhiên, chỉ một phần nhỏ của tài sản vô giá này là có sẵn để phân tích. Môi trường kho dữ liệu ( data warehouses ) truyền thống có kiến ​​trúc cứng nhắc, khó mở rộng quy mô cho các trường hợp sử dụng phân tích big data hiện đại. Các kho dữ liệu ( data warehouses ) này rất tốn kém để thiết lập và vận hành, đồng thời yêu cầu đầu tư rất lớn vào cả phần mềm và phần cứng.\nTrong bài viết này, chúng ta đã thảo luận về Amazon Redshift như một kho dữ liệu hiện đại có thể mở rộng, được quản lý hoàn toàn, có thể giúp bạn phân tích tất cả dữ liệu của mình và đạt được hiệu suất ở mọi quy mô với chi phí thấp và có thể dự đoán được. Để dịch chuyển kho dữ liệu của bạn sang Amazon Redshift, bạn cần xem xét một loạt các yếu tố, chẳng hạn như tổng kích thước của kho dữ liệu, tốc độ thay đổi dữ liệu và độ phức tạp của quá trình chuyển đổi dữ liệu, trước khi chọn một chiến lược và quy trình di chuyển phù hợp để giảm độ phức tạp và chi phí của dự án dịch chuyển kho dữ liệu của bạn. Với các dịch vụ AWS, chẳng hạn như AWS SCT và AWS DMS, và bằng cách áp dụng các mẹo và phương pháp hay nhất của các dịch vụ này, bạn có thể tự động hóa các nhiệm vụ dịch chuyển, quản lý quy mô dịch chuyển, đẩy nhanh việc thực hiện dự án dịch chuyển kho dữ liệu và làm hài lòng khách hàng của bạn.\n"
},
{
	"uri": "/vi/1-awsarchitectureblog/1.2-blog-2/",
	"title": "Dream11: Ngặn chặn các cuộc tấn công qui mô lớn ở lớp ứng dụng bằng AWS WAF",
	"tags": [],
	"description": "",
	"content": "Dream11: Ngặn chặn các cuộc tấn công qui mô lớn ở lớp ứng dụng bằng AWS WAF Là nền tảng fantasy sports lớn nhất thế giới với hơn 120 triệu người dùng, Dream11 chạy đồng thời nhiều contests trong khi xử lý hàng triệu yêu cầu của người dùng mỗi phút. Dream11 lấy người dùng làm chính và dữ liệu quan trọng của họ làm ưu tiên nhằm đảm bảo rằng ứng dụng Dream11 sẽ luôn bảo vệ người dùng trước tất cả các mối đe dọa và lỗ hổng bảo mật.\nGiới thiệu về AWS WAF Security Automations AWS WAF là một web application firewall giúp bảo vệ các ứng dụng và APIs khỏi các web exploits và bots phổ biến. Các cuộc tấn công này có thể ảnh hưởng đến tính khả dụng, xâm phạm bảo mật hoặc tiêu tốn quá nhiều tài nguyên của người dùng. AWS WAF cung cấp cho bạn quyền kiểm soát cách lưu lượng truy cập vào các ứng dụng của bạn. Bạn có thể tạo security rules nhằm kiểm soát lưu lượng truy cập của bot và chặn các mẫu tấn công phổ biến, chẳng hạn như SQL injection hoặc cross-site scripting (XSS).\nAWS WAF Security Automation sử dụng AWS CloudFormation để cấu hình nhanh các quy tắc AWS WAF giúp chặn các loại tấn công phổ biến sau:\n SQL injection Cross-site scripting HTTP floods Scanners and probes Known attacker origins (IP reputation lists) Bots and scrapers  Trong bài đăng trên blog này, chúng tôi sẽ giải thích cách Dream11 sử dụng AWS WAF Security Automations để bảo vệ ứng dụng của bạn khỏi các cuộc tấn công từ scanners và probes attacks.\nScanner và probe automation Để hiểu về scanner và probe automation, các bạn có thể xem một kịch bản tấn công thực tế đối với một ứng dụng cơ bản được AWS WAF bảo vệ. Giả sử rằng một kể tấn công đang cố gắng quét ứng dụng và xác định sơ hở bằng cách sử dụng công cụ tuỳ chỉnh của họ. Họ dự định tiến hành các cuộc tấn công injection (chẳng hạn như SQLi, XSS) hoặc các cuộc tấn công directory brute force.\nỨng dụng lúc này được bảo mật bởi AWS WAF, có các quy tắc để chặn các yêu cầu nếu phát hiện các signatures và patterns phù hợp. AWS WAF không có tất cả các payload để chặn tất cả các kiểu tấn công. Điều này có nghĩa là sau một số lần thử và gặp lỗi, kẻ tấn công có thể tìm thấy phần payload không bị AWS WAF chặn và cố gắng khai thác lỗ hổng.\nTrong trường hợp này, điều gì sẽ xảy ra nếu AWS WAF có thể phát hiện hành vi của các IP vi phạm và chặn nó trong một khoảng thời gian nhất định? Sẽ thật tuyệt nếu AWS WAF chặn IP của một kẻ tấn công sau khi nhận được một vài yêu cầu độc hại phải không? Bằng cách đó, các yêu cầu mới đến từ IP đó sẽ bị chặn mà AWS WAF không cần phải kiểm tra tất cả các quy tắc trong web ACL. Với mọi nỗ lực vượt qua thành công thì IP vi phạm cũng sẽ bị chặn ngay lập tức. Thay vì chặn IP vĩnh viễn, tính năng này chặn IP vi phạm trong một khoảng thời gian nhất định, không cho kẻ tấn công thực hiện thêm bất kỳ lần thử nào. Nó hoạt động như một bước đầu tiên của phản ứng khi xảy ra sự cố bảo mật. Đây là lúcitự động hóa sẽ giúp ích cho bạn.\nTính năng Scanner và probe automation giúp theo dõi Amazon CloudFront logs và phân tích mã trạng thái HTTP cho các yêu cầu đến từ các IP khác nhau. Dựa trên ngưỡng được cấu hình của HTTP status codes, scanner và probe automation sẽ cập nhật trực tiếp IP độc hại vào AWS WAF rule IPSet. Sau đó, nó sẽ chặn các yêu cầu tiếp theo từ IP đó trong một khoảng thời gian đã được định cấu hình.\nGiải pháp AWS WAF Security Automations tạo ra một AWS WAF rule, một AWS Lambda function và một truy vấn Scanner và Probes trên Amazon Athena. Câu truy vấn Athena sẽ phân tích vào Amazon CloudFront logs hoặc Application Load Balancer theo các khoảng thời gian đều đặn. Cứ mỗi phút, nó sẽ đếm số lượng yêu cầu bất thường từ các địa chỉ IP nguồn. Lambda function sẽ tiến hành cập nhật quy tắc AWS WAF IPSet để chặn thao tác scan từ các địa chỉ IP có tỷ lệ lỗi cao.\n Hình 1. Kiến trúc giải pháp scanner and probe automation (xxx thể hiện số liệu được định nghĩa theo từng trường hợp sử dụng )   Quy trình làm việc của giải pháp như sau, thể hiện trong Hình 1:\n Các CloudFront logs được đẩy vào Amazon S3 bucket. Log Parser Lambda sẽ chạy truy vấn Athena để tìm ngưỡng mã lỗi cho từng địa chỉ IP duy nhất. Nếu ngưỡng lỗi HTTP bị vượt qua đối với bất kỳ IP nào, thì Lambda function sẽ cập nhật IP vào trong AWS WAF IPSet trong một thời gian nhất định. IPSet tự động được bỏ chặn sau khi khoảng thời gian kết thúc.  Tùy chỉnh giải pháp AWS WAF Security Automation Scanner và probe automation với các quy tắc sẽ block traffic nếu tỷ lệ lỗi cho một địa chỉ IP cụ thể vượt qua ngưỡng. Sau đó, nó thêm IP vào IPSet bị chặn. IP này bị chặn trong một khoảng thời gian và chúng ta có thể tuỳ chỉnh cấu hình cho chúng (ví dụ: 12 giờ, 2 ngày, 1 tuần).\nTrong quá trình thiết lập AWS WAF cho Dream11, có những trường hợp yêu cầu ngoại lệ đối với quy tắc trước đó. Một là để ngăn chặn các internal services, hai là gateway IPs khỏi bị chặn bởi security automation. Chúng ta cần tùy chỉnh các quy tắc cho các ngưỡng được xác định trước này. Ví dụ: Solution nên chặn lưu lượng truy cập bên ngoài, nhưng exclude bất kỳ internal IP addresses nào.\nNhóm bảo mật Dream11 đã tùy chỉnh logic Lambda nhằm để phê duyệt tất cả các địa chỉ IPs của internal NAT gateway. Scanner and probe automation bỏ qua các IP này ngay cả khi có nhiều lỗi từ các IP đã được phê duyệt. Mã mẫu như sau:\nlog.info(\u0026#34;[update_ip_set] \\tIgnore the approved IP \u0026#34;)\rif ip_type == \u0026#34;IPV4\u0026#34; and source_ip not in outstanding_requesters[\u0026#39;ApprovedIPs\u0026#39;]: addresses_v4.append(source_ip)\relif ip_type == \u0026#34;IPV6\u0026#34; and source_ip not in outstanding_requesters[\u0026#39;ApprovedIPs\u0026#39;]: addresses_v6.append(source_ip) Lưu ý: Tạo tệp JSON với danh sách các IP được chấp thuận và lưu trữ trong APP_ACCESS_LOG_BUCKET Chúng tôi sẽ sử dụng cùng một S3 bucket để đặt các IP được phê duyệt dưới dạng tệp xyz.json, nơi chúng ta lưu trữ log truy cập CloudFront của mình. Điều này có thể định cấu hình trong file CloudFormation template dành cho Security Automation.\nGiải thích mã:  Trước tiên, custom code xác thực IP cụ thể mà ngưỡng lỗi được vượt quá , ngoại trừ các IP đã được phê duyệt. Nếu IP thuộc định dạng IPV4 hoặc IPV6 và không phải là IP được phê duyệt, thì IP đó sẽ được thêm vào IPSet bị chặn trong một khoảng thời gian nhất định.  Việc tùy chỉnh Lambda function sẽ cung cấp các giải pháp security automation mà điều đó sẽ không chặn bất kỳ request hợp lệ nào. Đồng thời, nó cung cấp khả năng bảo vệ chống lại các cuộc tấn công dạng scanner and probe. AWS WAF security automation là một giải pháp mã nguồn mở và được lưu trữ trên GitHub.\nKết luận Trong bài đăng trên blog này, chúng tôi đã đưa ra một cái nhìn tổng quan ngắn gọn về cách bạn có thể giảm thiểu các cuộc tấn công bằng cách sử dụng AWS WAF security automation chống lại scanner and probe attacks. Chúng tôi cũng đã minh họa sự tùy chỉnh được thực hiện bởi nhóm bảo mật Dream11.\nBằng cách tự động hóa các hoạt động bảo mật của mình, bạn sẽ cải thiện khả năng ứng phó sự cố hiệu quả. Bạn có thể sắp xếp thứ tự ưu tiên cho các mối đe dọa và xử lý các cuộc tấn công mạng một cách tự động với các hành động tự động. Điều này làm giảm nhu cầu can thiệp, giảm thời gian của bạn và nó có thể giải quyết các vấn đề bảo mật mà không cần các bạn ngồi làm thủ công.\nSau khi triển khai điều này tại Dream11, chúng ta đã có thể tạo các tuỳ chỉnh dành riêng cho ứng dụng cụ thể của mình để chặn các kiểu tấn công. Điều này đã cung cấp tính khả dụng của ứng dụng, bảo mật tài nguyên và ngăn chặn việc tiêu thụ tài nguyên quá mức. Với giải pháp này, chúng tôi có thể cung cấp trải nghiệm fantasy sports tốt nhất cho hơn 120 triệu người dùng.\n"
},
{
	"uri": "/vi/2-windowsonaws/",
	"title": "Windows on AWS",
	"tags": [],
	"description": "",
	"content": "Windows on AWS  Khởi chạy Microsoft Windows Server instances trên Amazon EC2 nhanh hơn tới 65% so với trước đây  "
},
{
	"uri": "/vi/3-networkingonaws/",
	"title": "Networking on AWS",
	"tags": [],
	"description": "",
	"content": "Networking on AWS  Giảm chi phí và tăng cường bảo mật với Amazon VPC Endpoints  "
},
{
	"uri": "/vi/1-awsarchitectureblog/1.3-blog-3/",
	"title": "Triển khai ứng dụng dựa trên Quarkus sử dụng AWS Lambda với AWS SAM",
	"tags": [],
	"description": "",
	"content": "Triển khai ứng dụng dựa trên Quarkus sử dụng AWS Lambda với AWS SAM Quarkus cung cấp cho các Java developers khả năng xây dựng native image dựa trên GraalVM. Native image là một tệp nhị phân bao gồm mọi thứ: mã nguồn, libraries, và một smaller virtual machine (VM). Cách tiếp cận này cải thiện thời gian khởi động các AWS Lambda function của bạn, vì nó được tối ưu hóa cho các môi trường dựa trên container. Những công cụ này sử dụng kiến trúc cloud native và serverless architectures với triết lý container-first.\nTrong bài đăng trên blog này, bạn tìm hiểu cách tích hợp Quarkus framework với các hàm AWS Lambda bằng cách sử dụng AWS Serverless Application Model (AWS SAM).\nGiảm chi phí hạ tầng và cải thiện độ trễ Khi bạn phát triển các ứng dụng với Quarkus và GraalVM với native images, file bootstrap được tạo cần nhiều thời gian hơn để biên dịch, nhưng nó sẽ có thời gian chạy nhanh hơn. GraalVM là một JIT compile tạo ra native machine code được tối ưu hoá, đồng thời sử dụng ít bộ nhớ và CPU hơn. Điều này đạt được nhờ một loạt các tối ưu hóa trình biên dịch tiên tiến và các kỹ thuật inlining tích cực và phức tạp. Bằng cách sử dụng Quarkus, bạn cũng có thể giảm chi phí cơ sở hạ tầng của mình vì bạn cần ít tài nguyên hơn.\nVới các tính năng Quarkus và AWS SAM, bạn có thể cải thiện hiệu suất độ trễ của các AWS Lambda function dựa trên Java của mình bằng cách giảm thời gian cold-start. Cold-start là thời gian khởi tạo mà một Lambda function thực hiện trước khi chạy mã thực. Sau khi function được khởi tạo lần đầu tiên, các yêu cầu trong tương lai sẽ sử dụng lại cùng một môi trường thực thi mà không phải chịu thời gian cold-start, giúp cải thiện hiệu suất.\nTổng quan giải pháp Hình 1 trình bày các thành phần AWS và quy trình làm việc của giải pháp của chúng tôi.\n Hình 1. Mô hình kiến trúc cho ứng dụng Quarkus (AWS Lambda)   Với AWS SAM, bạn có thể dễ dàng tích hợp các framework bên ngoài bằng cách sử dụng runtime tùy chỉnh và định cấu hình các thuộc tính trong file template và Makefile.\nChuẩn bị Trong bài hướng dẫn này, bạn cần phải có đủ các điều kiện như sau:\n Software components: Java 11 JDK (ví dụ như Amazon Corretto), Maven, và AWS SAM CLI phiên bản mới nhất. Quyền admin của các dịch vụ sau : AWS Lambda, Amazon CloudWatch, Amazon API Gateway, và AWS Identity and Access Management. Bạn nên áp dụng nguyên tắc quyền tối thiểu trong trường hợp sử dụng của riêng bạn, đó là một best practice được khuyến nghị bởi AWS.  Tạo một AWS Lambda function dựa trên Java AWS SAM cung cấp các templates để rút ngắn thời gian khi làm các hàm mới. Tạo một function Java-based bằng cách làm theo các bước sau:\nChạy câu lệnh sau trong terminal của bạn:\nsam init -a x86_64 -r java11 -p Zip -d maven -n java11-mvn-default Trong các parameters này chúng ta chọn kiến trúc x86, java11 làm Java runtime LTS version, Zip làm build artifact và Maven làm công cụ package và dependency. Chúng ta cũng thiết lập tên dự án.\nHãy chọn tuỳ chọn đầu tiên để sử dụng cho base code của bạn:\n1 – AWS Quick Start Templates\nCuối cùng, với lựa chọn trước đó, bạn có các templates khác nhau để lựa chọn mà tạo base structure cho function của bạn. Trong trường hợp của chúng ta, hãy chọn cái đầu tiên, function này tạo ra một AWS Lambda function gọi tới là external HTTPS endpoint. Thao tác này sẽ lấy địa chỉ IP và trả lại nó với phản hồi “Hello World” cho người dùng trong JSON:\n1 – Hello World Example\nOutput sẽ mang lại kết quả như sau, thể hiện trong Hình 2:\n Hình 2. Cấu hình dữ liệu đầu vào cho AWS SAM    Tích hợp Quarkus framework Sử dụng AWS SAM, bạn có thể dễ dàng tích hợp các non-AWS custom runtimes trong các AWS Lambda function của mình. Với tính năng này, bạn có thể tích hợp Quarkus framework. Làm theo bốn bước tiếp theo:\n1. Tạo một Makefile file Tạo file “Makefile” trong thư mục “HelloWorldFunction” với code như sau:\nbuild-HelloWorldFunction:\rmvn clean package -Pnative -Dquarkus.native.container-build=true -Dquarkus.native.builder-image=quay.io/quarkus/ubi-quarkus-mandrel:21.3-java11\r@ unzip ./target/function.zip -d $(ARTIFACTS_DIR) Với snippet này, bạn đang định cấu hình AWS SAM để tạo bootstrap runtime bằng cách sử dụng Maven instructions cho AWS SAM.\nSử dụng Quarkus, bạn có thể xây dựng tệp Linux executable mà không cần phải cài đặt GraalVM với tùy chọn tiếp theo:\n-Dquarkus.native.container-build=true 2. Cấu hình Maven dependencies Với tư cách là một dự án của Maven, nó sẽ bao gồm các dependencies cần thiết. Thay đổi file pom.xml trong thư mục \u0026ldquo;HelloWorldFunction\u0026rdquo; để loại bỏ các thư viện mặc định:\n\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.amazonaws\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aws-lambda-java-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.amazonaws\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aws-lambda-java-events\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.6.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt; Thêm các Quarkus libraries, profile, và plugins vào bên phải phần pom.xml như được hiển thị trong cấu hình XML sau. Tại thời điểm hiện tại, phiên bản mới nhất của Quarkus là 2.7.1.Final. Chúng tôi thực sự khuyên bạn nên sử dụng các phiên bản mới nhất của các libraries and plugins:\n\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.quarkus\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;quarkus-amazon-lambda\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.quarkus\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;quarkus-arc\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;4.13.1\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;build\u0026gt;\r\u0026lt;finalName\u0026gt;function\u0026lt;/finalName\u0026gt;\r\u0026lt;plugins\u0026gt;\r\u0026lt;plugin\u0026gt;\r\u0026lt;groupId\u0026gt;io.quarkus\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;quarkus-maven-plugin\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.7.1.Final\u0026lt;/version\u0026gt;\r\u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt;\r\u0026lt;executions\u0026gt;\r\u0026lt;execution\u0026gt;\r\u0026lt;goals\u0026gt;\r\u0026lt;goal\u0026gt;build\u0026lt;/goal\u0026gt;\r\u0026lt;goal\u0026gt;generate-code\u0026lt;/goal\u0026gt;\r\u0026lt;goal\u0026gt;generate-code-tests\u0026lt;/goal\u0026gt;\r\u0026lt;/goals\u0026gt;\r\u0026lt;/execution\u0026gt;\r\u0026lt;/executions\u0026gt;\r\u0026lt;/plugin\u0026gt;\r\u0026lt;/plugins\u0026gt;\r\u0026lt;/build\u0026gt;\r\u0026lt;profiles\u0026gt;\r\u0026lt;profile\u0026gt;\r\u0026lt;id\u0026gt;native\u0026lt;/id\u0026gt;\r\u0026lt;activation\u0026gt;\r\u0026lt;property\u0026gt;\r\u0026lt;name\u0026gt;native\u0026lt;/name\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/activation\u0026gt;\r\u0026lt;properties\u0026gt;\r\u0026lt;quarkus.package.type\u0026gt;native\u0026lt;/quarkus.package.type\u0026gt;\r\u0026lt;/properties\u0026gt;\r\u0026lt;/profile\u0026gt;\r\u0026lt;/profiles\u0026gt; 3. Cấu hình template.yaml sử dụng previous Makefile Để cấu hình AWS SAM template nhằm sử dụng cấu hình Makefile của riêng bạn bằng cách sử dụng các hướng dẫn của Quarkus và Maven một cách chính xác, hãy chỉnh sửa tệp template.yaml để thêm các thuộc tính sau:\nResources:\rHelloWorldFunction:\rMetadata:\rBuildMethod: makefile\rProperties:\rRuntime: provided 4. Thêm một file properties để bật tính năng cấu hình SSL Cuối cùng, tạo một tệp application.properties trong thư mục: ../HelloWorldFunction/src/main/resources/ với thuộc tính sau:\nquarkus.ssl.native=true property này là cần thiết vì function mẫu sử dụng kết nối an toàn đến https://checkip.amazonaws.com. Nó sẽ lấy nội dung phản hồi trong mẫu bạn đã chọn trước đó.\nGiờ đây, bạn có thể xây dựng và triển khai hàm Quarkus đầu tiên của mình bằng các lệnh AWS SAM sau:\nsam build Thao tác này sẽ tạo Zip artifact bằng cách sử dụng Maven tool và sẽ build the native image để triển khai trên AWS Lambda dựa trên cấu hình Makefile trước đó của bạn. Cuối cùng, chạy lệnh AWS SAM sau để triển khai function của bạn:\nsam deploy -–guided Lần đầu tiên bạn deploy một ứng dụng AWS SAM, bạn có thể tùy chỉnh một số tham số như Stack name, AWS Region và nhiều hơn thế nữa (xem Hình 3). Bạn cũng có thể chọn một trong những tham số mặc định. Để biết thêm thông tin về các tùy chọn triển khai AWS SAM, hãy đọc AWS SAM documentation.\n Hình 3. Cấu hình đầu vào cho việc deploy Lambda function   Cấu hình này cho phép bạn định cấu hình các quyền IAM cần thiết để deploy tài nguyên AWS SAM cho code mẫu này. Sau khi hoàn thành nhiệm vụ, bạn có thể nhìn thấy AWS CloudFormation Stack và các tài nguyên được tạo bởi AWS SAM.\nBây giờ bạn đã tạo và triển khai một HTTPS API Gateway endpoint với ứng dụng Quarkus trên AWS Lambda mà bạn có thể thực hiện chạy kiểm tra.\nKiểm tra Quarkus function Cuối cùng, hãy kiểm tra Quarkus function của bạn trong AWS Management Console bằng cách chọn new function trong danh sách các function của AWS Lambda. Sử dụng tính năng kiểm tra có trong bảng điều khiển, như trong Hình 4:\n Hình 4. Thực thi test mẫu trong Lambda   Bạn sẽ nhận được phản hồi cho request vào Lambda function của mình và một bản tóm tắt. Điều này bao gồm thông tin như thời lượng hoặc các tài nguyên cần thiết trong Quarkus function mới của bạn. Để biết thêm thông tin về việc kiểm tra ứng dụng trên AWS SAM, bạn có thể đọc Testing and debugging serverless applications.. Bạn cũng có thể truy cập trang web chính thức để đọc thêm AWS SAM with Quarkus.\nDọn dẹp tài nguyên Dọn dẹp tài nguyên Để tránh phát sinh các khoản phí trong tương lai, hãy xóa các tài nguyên đã tạo trong AWS Lambda stack của bạn. Bạn có thể xóa tài nguyên bằng lệnh sau:\nsam delete Kết luận Trong bài viết này, chúng tôi đã trình bày cách tích hợp các Java frameworks như Quarkus trên AWS Lambda bằng cách sử dụng custom runtimes với AWS SAM. Điều này cho phép bạn cấu hình custom build configurations hoặc các frameworks ưa thích của bạn. Các công cụ này sẽ trau dồi kinh nghiệm cho các developer, các công cụ tiêu chuẩn được sử dụng để phát triển các ứng dụng serverless với các yêu cầu trong tương lai, cho thấy tính linh hoạt mạnh mẽ cho các developers.\nQuarkus native image được tạo và áp dụng trong AWS Lambda function làm giảm kích thước Java footprint. Bạn có thể sử dụng các kĩ năng về Java của mình để phát triển các ứng dụng không cần máy chủ mà không cần phải thay đổi ngôn ngữ lập trình. Đây là một lợi thế lớn khi các nguồn lực tính toán hoặc vấn đề cold-start rất quan trọng đối với các yêu cầu kinh doanh hoặc kỹ thuật.\n"
},
{
	"uri": "/vi/4-dataanalytics/",
	"title": "Data Analytics on AWS",
	"tags": [],
	"description": "",
	"content": "Data Analytics on AWS  Những điều cần quan tâm khi dịch chuyển Data warehouse lên Amazon Redshift  "
},
{
	"uri": "/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]